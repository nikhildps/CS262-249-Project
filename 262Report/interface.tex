The key primitive in our Global Data Plane prototype is the append only log. This data structure exposes two main functions to the user:
\begin{enumerate}
\item \texttt{append(log\_name)}: Adds a new entry to the end of the log with the specified name. If the log does not exist, it is automatically created at the appropriate storage server.
\item \texttt{read(log\_name, entry\_num)}: Retrieves the specified entry from the log with the given name. Log entries are specified by index, starting from 1.
\end{enumerate}
Our prototype deals with data in the form of opaque byte arrays. Thus, the system is entirely agnostic about the format of the data it stores. While we specifically use JSON in our test cases described below, log entries theoretically can contain data in whatever format is most convenient for the end user. This sort of flexibility was one of the key design goals of our system.

Additional flexibility is achieved through the use of common access APIs (CAAPIs). While an append only log is a convenient data structure at the system level, it is not particularly convenient for end users, who may want to interact with a more sophisticated interface such as a key/value store. A CAAPI is responsible for bridging this divide. It exposes a convenient interface to end users and translates between operations offered by this interface and log operations. Hence, a CAAPI maintains two views of the same data. The first is the underlying append only log, which is viewed as the ground truth, while the second view is materialized from this log and exposed to end users. This sort of approach is common in the database community \cite{aries}, where operations are often performed on a write-ahead log before they are reflected in the on-disk representation of the actual database tables.

As an example CAAPI, consider a key-value store. A \texttt{put} operation on the key-value store would translate to an \texttt{append} on the underlying log, while a \texttt{get} operation translates to a \texttt{read}. The CAAPI layer must maintain an index mapping the most recent value for each key to the proper log entry. Furthermore, the key/value store can be maintained as soft state that is recovered from the underlying log when necessary. Checkpoints can be used to expedite this process if the log becomes especially large.