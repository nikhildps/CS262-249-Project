In our current implementation, the hash of a log's external name determines not only its internal identifier, but also the server at which that log must be stored. Thus, routing and storage and coupled together. However, it is possible to add another layer of indirection such that the hash of a log's name determines only which server is responsible for knowing where the log is stored rather than being responsible for storing the data itself. While this adds an extra hop to any route in the system, it also allows logs to be stored at arbitrary GDP servers. This in turn enables important features like intelligent placement of data to maximize locality and migration of logs to adapt to changing usage patterns.

In order to make this decoupling possible, the system must also incorporate a log advertisement scheme such that GDP servers can communicate with their peers about which logs are stored where. When a new log is created at a particular server, for example, that server must advertise this fact to the servers responsible for tracking the location of that log. When subsequent requests to modify or access the log are routed through the overlay network, they will eventually encounter a server that has received this information and thus be able to contact the server where the log is stored.

Another important area of future work is the implementation publish-subscribe semantics. This is an important feature that we imagine will play an important role in the Global Data Plane. In order to implement subscriptions efficiently, it will most likely be necessary to use some kind of multicast scheme that intelligently delivers data to all subscribers for a particular log. In addition, we imagine that the GDP will eventually consist of both storage servers as well as nodes dedicated only to routing. These route nodes could be implemented using something like Click. \cite{click} This could enable more efficient and more customizable routing schemes that can enforce quality of service guarantees.